## 1.4 并发编程

>date: 2019-01-28

![](../assets/images/14.jpg)

### 1.4.1 GIL锁

`Python` 提供了`multiprocessing`和`threading`模块可用于多进程和多线程开发。

多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。

在 `Python` 中，运行多线程程序，每个线程都会被上一把锁，以防止每个线程因为共享资源，交替运行而乱改数据。这个锁就是**全局解释锁（`GIL`）**，那`GIL`怎么用呢，这里引用[廖雪峰博客](https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/00143192823818768cd506abbc94eb5916192364506fa5d000)里的一个例子。

```python
lock = threading.Lock()

def run_thread(n):
    for i in range(100000):
        # 先要获取锁:
        lock.acquire()
        try:
            # 进行一些操作:
            change_it(n)
        finally:
            # 操作完了一定要释放锁:
            lock.release()
```

当多个线程同时执行`lock.acquire()`时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。

获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用`try...finally`来确保锁一定会被释放。

锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。

另外，比如说我们有一个`4`核的`CPU`，那么这样一来，在单位时间内每个核只能跑一个线程，然后时间片轮转切换。**但是`Python`不一样，它不管你有几个核，单位时间多个核只能跑一个线程，然后时间片轮转。看起来很不可思议？但是这就是`GIL`搞的鬼。**任何Python线程执行前，必须先获得`GIL`锁，然后，每执行`100`条字节码，解释器就自动释放`GIL`锁，让别的线程有机会执行。这个`GIL`全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使`100`个线程跑在`100`核`CPU`上，也只能用到`1`个核。通常我们用的解释器是官方实现的`CPython`，要真正利用多核，除非重写一个不带`GIL`的解释器。

把Python的`GIL`说得这么差，那有没有啥办法可以解决，有！使用多进程！多个Python进程有各自独立的`GIL`锁，互不影响，这样就不怕程序里的数据改乱了。

### 1.4.2 多进程

**进程:**

> 进程是系统进行资源分配和调度的最小单位，是操作系统结构的基础。在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。

**多进程:**

> 同一个时间里，同一个计算机系统中允许两个或两个以上的进程处于并行状态，这是多进程。
>
> 多进程带来的好处是你可以边听`mp3`边上网，与此同时甚至可以将下载的文档打印出来，而这些任务之间丝毫不会相互干扰。但并行需要解决的问题是通常并行的进程比`CPU`数量多得多，而原则上一个`CPU`只能分配给一个进程（引入线程后，`CPU`调度的基本单位是线程，进程是资源分配的最小单位），以便运行这个进程。而要让`CPU`同时运行多个进程，就必须使用并发技术，实现并发技术最常见的就是时间片轮转调度算法，即在操作系统的管理下，所有正在运行的进程轮流使用`CPU`，每个进程允许占用`CPU`的时间非常短(比如`1`毫秒)，这样用户根本感觉不出来 `CPU`是在轮流为多个进程服务，就好象所有的进程都在不间断地运行一样，给用户的感觉就是并行。但实际上在任何一个时间内有且仅有一个进程占有`CPU`。 

**`Python` 中使用多进程：**

```python
import multiprocessing
import time

# 创建函数并将其作为多个进程

def worker_1(interval):
    print("worker_1")
    time.sleep(interval)
    print("end worker_1")

def worker_2(interval):
    print("worker_2")
    time.sleep(interval)
    print("end worker_2")

def worker_3(interval):
    print("worker_3")
    time.sleep(interval)
    print("end worker_3")

if __name__ == "__main__":
    p1 = multiprocessing.Process(target = worker_1, args = (2,))
    p2 = multiprocessing.Process(target = worker_2, args = (3,))
    p3 = multiprocessing.Process(target = worker_3, args = (4,))

    p1.start()
    p2.start()
    p3.start()
    
    # CPU 核心数
    print(("The number of CPU is:" + str(multiprocessing.cpu_count())))

    for p in multiprocessing.active_children():
        print(("child p.name:" + p.name + "  p.id" + str(p.pid)))

    p1.join()
    p2.join()
    p3.join()
    print("END")
```

**结果:**

```python
The number of CPU is:4  #CPU核心数视具体运行环境而定
child p.name:Process-3  p.id1569
child p.name:Process-2  p.id1568
child p.name:Process-1  p.id1567
worker_1
worker_2
worker_3
end worker_1
end worker_2
end worker_3
END
```

### 1.4.3 多线程

**线程:**

> 线程是 `CPU` 调度和分配的基本单位。线程是建立在进程的基础上的一次程序运行单位。
>
简单的说，进程是线程的容器，线程运行在进程之下，一个进程里面可以有多个线程。就像开了一个`QQ`程序，你可以聊天，也可以视频，还可以远程操作。这里运行一个`QQ`程序就相当于开了一个进程，而像聊天，视频这些就相当于是线程(当然，实际上程序的资源分配和调度可能要复杂得多，这里只做一个简单比喻)。

**多线程:**

> 一个进程中可以有多条执行路径同时执行，一个线程就是进程中的一条执行路径。
>
> 在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。它相当于一个进程里只有一个线程，进程本身就是线程。所以线程有时被称为轻量级进程(`Lightweight Process`，`LWP`）。后来，随着计算机的发展，对多个任务之间上下文切换的效率要求越来越高，就抽象出一个更小的概念——线程，一般一个进程会有多个(也可是一个)线程。

**`Python` 中使用多线程:**

```python
# 以下代码引用自廖雪峰博客
import time, threading

# 新线程执行的代码:
def loop():
    print('thread %s is running...' % threading.current_thread().name)
    n = 0
    while n < 5:
        n = n + 1
        print('thread %s >>> %s' % (threading.current_thread().name, n))
        time.sleep(1)
    print('thread %s ended.' % threading.current_thread().name)

print('thread %s is running...' % threading.current_thread().name)
t = threading.Thread(target=loop, name='LoopThread')
t.start()
t.join()
print('thread %s ended.' % threading.current_thread().name)
```

**结果:**

```python
thread MainThread is running...
thread LoopThread is running...
thread LoopThread >>> 1
thread LoopThread >>> 2
thread LoopThread >>> 3
thread LoopThread >>> 4
thread LoopThread >>> 5
thread LoopThread ended.
thread MainThread ended.
```

### 1.4.4 计算密集型&&IO密集型

**计算密集型：**

> 计算密集型任务的特点是要进行大量的计算，消耗`CPU`资源，比如计算圆周率、对视频进行高清解码等等，全靠`CPU`的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，`CPU`执行任务的效率就越低，所以，要最高效地利用`CPU`，计算密集型任务同时进行的数量应当等于`CPU`的核心数。
>
> 计算密集型任务由于主要消耗`CPU`资源，因此，代码运行效率至关重要。`Python`这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用`C`语言编写。

**`IO` 密集型：**

> 涉及到网络、磁盘`IO`的任务都是`IO`密集型任务，这类任务的特点是`CPU`消耗很少，任务的大部分时间都在等待`IO`操作完成（因为`IO`的速度远远低于`CPU`和内存的速度）。对于`IO`密集型任务，任务越多，`CPU`效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如`Web`应用。
>
> `IO`密集型任务执行期间，`99%`的时间都花在`IO`上，花在`CPU`上的时间很少，因此，用运行速度极快的`C`语言替换用`Python`这样运行速度极低的脚本语言，完全无法提升运行效率。对于`IO`密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，`C`语言最差。

综上，`Python`多线程相当于单核多线程，多线程有两个好处：`CPU`并行，`IO`并行，单核多线程相当于自断一臂。所以，在`Python`中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过`C`扩展来实现，不过这样就失去了`Python`简单易用的特点。不过，也不用过于担心，`Python`虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个`Python`进程有各自独立的`GIL`锁，互不影响。

### 1.4.5 协程

**协程:**

> 协程，又称微线程，纤程，英文名`Coroutine`。协程的作用，是在执行函数`A`时，可以随时中断，去执行函数`B`，然后中断继续执行函数`A`（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行。 **`Python`对协程的支持是通过`generator`实现的。**

### 1.4.6 `IO`模型

> `IO`模型按照主流区分共有以下几种：
>
> * **同步模型(`synchronous IO`)**
> * 阻塞IO（`bloking IO`）
> * 非阻塞IO（`non-blocking IO`）
> * 多路复用IO（`multiplexing IO`）
> * 信号驱动式IO（`signal-driven IO`）
> 
> * **异步`IO`（`asynchronous IO`）**

**基本 `Linux IO` 模型的简单矩阵:**

![IO 矩阵](../assets/images/146_01.png)

* * *

**同步阻塞`IO`**

> 同步阻塞 `IO` 模型是最常用的一个模型，也是最简单的模型。在`Linux`中，默认情况下所有的`socket`都是`blocking`。它符合人们最常见的思考逻辑。阻塞就是进程 "被" 休息, `CPU`处理其它进程去了。
> 
> 在这个`IO`模型中，用户空间的应用程序执行一个系统调用（`recvform`），这会导致应用程序阻塞，什么也不干，直到数据准备好，并且将数据从内核复制到用户进程，最后进程再处理数据，在等待数据到处理数据的两个阶段，整个进程都被阻塞。不能处理别的网络`IO`。调用应用程序处于一种不再消费 `CPU` 而只是简单等待响应的状态，因此从处理的角度来看，这是非常有效的。在调用`recv()/recvfrom()`函数时，发生在内核中等待数据和复制数据的过程，大致如下图：

![同步阻塞IO](../assets/images/146_02.png)

当用户进程调用了`recv()/recvfrom()`这个系统调用，`kernel`就开始了`IO`的第一个阶段：准备数据（对于网络`IO`来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的`UDP`包。这个时候`kernel`就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。第二个阶段：当`kernel`一直等到数据准备好了，它就会将数据从`kernel`中拷贝到用户内存，然后`kernel`返回结果，用户进程才解除`block`的状态，重新运行起来。

* * *

**同步非阻塞IO**

> 同步非阻塞就是 “每隔一会儿瞄一眼进度条” 的轮询（`polling`）方式。在这种模型中，设备是以非阻塞的形式打开的。这意味着 `IO` 操作不会立即完成，`read` 操作可能会返回一个错误代码，说明这个命令不能立即满足（`EAGAIN` 或 `EWOULDBLOCK`）。
> 
> 在网络`IO`时候，非阻塞`IO`也会进行`recvform`系统调用，检查数据是否准备好，与阻塞`IO`不一样，"非阻塞将大的整片时间的阻塞分成`N`多的小的阻塞, 所以进程不断地有机会 '被' `CPU`光顾"。
> 
> 也就是说非阻塞的`recvform`系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个`error`。进程在返回之后，可以干点别的事情，然后再发起`recvform`系统调用。重复上面的过程，循环往复的进行`recvform`系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。

在`Linux`下，可以通过设置`socket`使其变为`non-blocking`。当对一个`non-blocking socket`执行读操作时，流程如图所示：

![同步非阻塞](../assets/images/146_03.png)

当用户进程发出`read`操作时，如果`kernel`中的数据还没有准备好，那么它并不会`block`用户进程，而是立刻返回一个`error`。从用户进程角度讲，它发起一个`read`操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个`error`时，它就知道数据还没有准备好，于是它可以再次发送`read`操作。一旦`kernel`中的数据准备好了，并且又再次收到了用户进程的`system call`，那么它马上就将数据拷贝到了用户内存，然后返回。

* * *

**IO多路复用**

> 由于同步非阻塞方式需要不断主动轮询，轮询占据了很大一部分过程，轮询会消耗大量的CPU时间，而 “后台” 可能有多个任务在同时进行，人们就想到了循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。如果轮询不是进程的用户态，而是有人帮忙就好了。那么这就是所谓的 “`IO` 多路复用”。`UNIX/Linux` 下的 `select`、`poll`、`epoll` 就是干这个的（`epoll` 比 `poll`、`select` 效率高，做的事情是一样的）。
> 
> `IO`多路复用有两个特别的系统调用`select`、`poll`、`epoll`函数。`select`调用是内核级别的，`select`轮询相对非阻塞的轮询的区别在于---前者可以等待多个`socket`，能实现同时对多个`IO`端口进行监听，当其中任何一个`socket`的数据准备好了，就能返回进行可读，然后进程再进行`recvform`系统调用，将数据由内核拷贝到用户进程，当然这个过程是阻塞的。`select`或`poll`调用之后，会阻塞进程，与`blocking IO`阻塞不同在于，此时的`select`不是等到`socket`数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理。如何知道有一部分数据到达了呢？监视的事情交给了内核，内核负责数据到达的处理。也可以理解为"非阻塞"吧。
> 
> `I/O`复用模型会用到`select`、`poll`、`epoll`函数，这几个函数也会使进程阻塞，但是和阻塞`I/O`所不同的的，这两个函数可以同时阻塞多个`I/O`操作。而且可以同时对多个读操作，多个写操作的`I/O`函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用`I/O`操作函数。
> 
> **`IO`多路复用与同步非阻塞`IO`的区别在于，多路复用能够使用`select` 或 `poll` 或 `epoll` 函数监听多个`IO`的事件流，但同步非阻塞`IO`只能监听一个`IO`。而 `select` 与 `epoll` 也有差别，`select`是无差别轮询所有流，它只知道有`IO`事件发生，但是哪些流发生了`IO`事件并不清楚，`select`只是告诉你一定数目的流有事件了，至于哪个流有事件，还得你一个一个地去轮询，而`epoll`会把发生的事件告诉你，通过发生的事件，就自然而然定位到哪个流了。**
> 
> **`Apache`采用 `select`，`select` 时间复杂度`O(n)`；`Nginx`采用 `epoll`，`epoll`时间复杂度`O(1)`**

![IO多路复用](../assets/images/146_04.png)

`IO multiplexing`就是我们说的`select`，`poll`，`epoll`，有些地方也称这种IO方式为`event driven IO`。`select/epoll`的好处就在于单个`process`就可以同时处理多个网络连接的`IO`。它的基本原理就是`select`，`poll`，`epoll`这个`function`会不断的轮询所负责的所有`socket`，当某个`socket`有数据到达了，就通知用户进程。
当用户进程调用了`select`，那么整个进程会被`block`，而同时，`kernel`会“监视”所有`select`负责的`socket`，当任何一个`socket`中的数据准备好了，`select`就会返回。这个时候用户进程再调用`read`操作，将数据从`kernel`拷贝到用户进程。

多路复用的特点是通过一种机制一个进程能同时等待`IO`文件描述符，内核监视这些文件描述符（套接字描述符），其中的任意一个进入读就绪状态，`select`， `poll`，`epoll`函数就可以返回。

* * *

**信号驱动式`IO`**

> 信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。过程如下图所示：

![IO多路复用](../assets/images/146_05.png)

* * *

**异步非阻塞 `IO`**
> 相对于同步`IO`，异步`IO`不是顺序执行。用户进程进行`aio_read`系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到`socket`数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。`IO`两个阶段，进程都是非阻塞的。
> 
> 异步过程如下图所示：

![IO多路复用](../assets/images/146_06.png)

用户进程发起`aio_read`操作之后，立刻就可以开始去做其它的事。而另一方面，从`kernel`的角度，当它受到一个`asynchronous read`之后，首先它会立刻返回，所以不会对用户进程产生任何`block`。然后，`kernel`会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，`kernel`会给用户进程发送一个`signal`或执行一个基于线程的回调函数来完成这次 `IO` 处理过程，告诉它`read`操作完成了。
在 `Linux` 中，通知的方式是 “信号”：

如果这个进程正在用户态忙着做别的事（例如在计算两个矩阵的乘积），那就强行打断之，调用事先注册的信号处理函数，这个函数可以决定何时以及如何处理这个异步任务。由于信号处理函数是突然闯进来的，因此跟中断处理程序一样，有很多事情是不能做的，因此保险起见，一般是把事件 “登记” 一下放进队列，然后返回该进程原来在做的事。
如果这个进程正在内核态忙着做别的事，例如以同步阻塞方式读写磁盘，那就只好把这个通知挂起来了，等到内核态的事情忙完了，快要回到用户态的时候，再触发信号通知。
如果这个进程现在被挂起了，例如无事可做 `sleep` 了，那就把这个进程唤醒，下次有 `CPU` 空闲的时候，就会调度到这个进程，触发信号通知。

异步 `API` 说来轻巧，做来难，这主要是对 `API` 的实现者而言的。`Linux` 的异步 `IO（AIO）`支持是 `2.6.22` 才引入的，还有很多系统调用不支持异步 `IO`。`Linux` 的异步 `IO` 最初是为数据库设计的，因此通过异步 `IO` 的读写操作不会被缓存或缓冲，这就无法利用操作系统的缓存与缓冲机制。

* * *

**`IO`模型总结**

> **`blocking`和`non-blocking`区别**
> 
> 调用`blocking IO`会一直`block`住对应的进程直到操作完成，而`non-blocking IO`在`kernel`还准备数据的情况下会立刻返回。
> 
> **`synchronous IO`和`asynchronous IO`区别**
> 
> 在说明`synchronous IO`和`asynchronous IO`的区别之前，需要先给出两者的定义。`POSIX`的定义是这样子的：
> 
> `A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;An asynchronous I/O operation does not cause the requesting process to be blocked;`
> 
> 两者的区别就在于`synchronous IO`做“`IO operation`”的时候会将`process`阻塞。按照这个定义，之前所述的`blocking IO`，`non-blocking IO`，`IO multiplexing`都属于`synchronous IO`。
> 
> 有人会说，`non-blocking IO`并没有被`block`啊。这里有个非常“狡猾”的地方，定义中所指的“`IO operation`”是指真实的`IO`操作，就是例子中的`recvfrom`这个`system call`。`non-blocking IO`在执行`recvfrom`这个`system call`的时候，如果`kernel`的数据没有准备好，这时候不会`block`进程。但是，当`kernel`中数据准备好的时候，`recvfrom`会将数据从`kernel`拷贝到用户内存中，这个时候进程是被`block`了，在这段时间内，进程是被`block`的。而`asynchronous IO`则不一样，当进程发起`IO` 操作之后，就直接返回再也不理睬了，直到`kernel`发送一个信号，告诉进程说`IO`完成。在这整个过程中，进程完全没有被`block`。


各个`IO Model`的比较如图所示：

![总结](../assets/images/146_07.png)

### 1.4.7 CPython


参考链接：

* [廖雪峰的网站](https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014319272686365ec7ceaeca33428c914edf8f70cca383000)
* [简书博客](https://www.jianshu.com/p/486b0965c296)
