## 6.1 分布式系统

>date: 2019-05-06

![](../assets/images/61.jpg)

### 6.1.1 基础理论

分布式系统是作为单个完整服务展现在终端用户面前的一组协同工作服务器。组中的服务器共享状态、同步操作，并且任意某个服务器独立故障时都不会影响整个系统的正常运行。

* 分布式和集群

分布式：将一个业务员拆分不同的子业务，分布在不同的机器上执行；

集群：多台服务器集中在一起，实现同一业务，可以视为一台计算机。

但是分布式的每一个节点，都可以用来做集群，但是集群不一定是分布式的。

* `SOA`和微服务架构

`SOA`：面向服务的架构，这是一种设计理念，其中包含多个服务，服务之间通过相互依赖最终提供一系列完整的功能。

微服务：类似`SOA`架构，但是更加强调业务彻底的组件化和服务化，单个业务系统会被拆分为可以独立开发、设计、部署的小应用。

* `PV`、`TPS`、`QPS`

`PV`：访问量即`Page View`, 即页面浏览量或点击量，用户每次刷新即被计算一次。

单台服务器每天PV计算：`每天总PV = QPS * 3600 * 6`；`每天总PV = QPS * 3600 * 8`。

`TPS`：`Transactions Per Second`（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。`业务TPS = CAPS × 每个呼叫平均TPS`。

`TPS`是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力最低模块的`TPS`值。

`QPS`：每秒查询率`QPS`是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应`fetches/sec`，即每秒的响应请求数，也即是最大吞吐能力。

### 6.1.2 可伸缩和可扩展

* 垂直扩展和水平扩展

1. 垂直扩展：在系统现有的部件上下工夫，通过提高某个部件的性能（或速度）来提高负载能力的。

2. 水平扩展：通过增加更多的系统成员（性能或速度还是原来的一样）来提高负载能力的。

* 可伸缩

伸缩性是指在不改变原有架构设计的基础上，通过添加/减少硬件（服务器）的方式，提高/降低系统的处理能力。

1. 应用层：对应用进行垂直或水平切分。然后针对单一功能进行负载均衡（`DNS`,`HTTP`[反向代理],`IP`,链路层）。

2. 服务层：与应用层类似。

3. 数据层：分库，分表，`NOSQL`等；常用算法`Hash`，一致性`Hash`。

* 可扩展

可以方便的进行功能模块的新增/移除，提供代码/模块级别良好的可扩展性。

1. 模块化，组件化：高内聚，内耦合，提高复用性，扩展性。

2. 稳定接口：定义稳定的接口，在接口不变的情况下，内部结构可以“随意”变化。

3. 设计模式：应用面向对象思想，原则，使用设计模式，进行代码层面的设计。

4. 消息队列：模块化的系统，通过消息队列进行交互，使模块之间的依赖解耦。

5. 分布式服务：公用模块服务化，提供其他系统使用，提高可重用性，扩展性。

### 6.1.3 高可用

#### 负载均衡

负载均衡 （`Load Balance`），其意思就是将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行。需要我们注意的是：它并不属于网络基础架构，而是属于一种网络优化设备。它是建立在现有的网络基础架构之上，给企业提供了更廉价更有效的扩展选择。

* 硬件

硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器，由于专门的设 备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求。

优点：能够直接通过智能交换机实现,处理能力更强，而且与系统无关，负载性能强更适用于一大堆设备、大访问量、简单应用。

缺点：成本高，除设备价格高昂，而且配置冗余．很难想象后面服务器做一个集群，但最关键的负载均衡设备却是单点配置；无法有效掌握服务器及应用状态。
硬件负载均衡，一般都不管实际系统与应用的状态，而只是从网络层来判断，所以有时候系统处理能力已经不行了，但网络可能还来得及反应（这种情况非常典型，比如应用服务器后面内存已经占用很多，但还没有彻底不行，如果网络传输量不大就未必在网络层能反映出来）。

* 软件

软件负载均衡解决方案是指在一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。

目前比较流行的就三类软件负载均衡，`LVS`、`Nginx`和`HAProxy`。用的最多的还是`LVS`和`Nginx`这两种。

优点：基于系统与应用的负载均衡，能够更好地根据系统与应用的状况来分配负载。这对于复杂应用是很重要的，性价比高，实际上如果几台服务器，用F5之类的硬件产品显得有些浪费，而用软件就要合算得多，因为服务器同时还可以跑应用做集群等。

缺点：负载能力受服务器本身性能的影响，性能越好，负载能力越大。

* 负载均衡算法

1. 静态负载均衡算法

轮询（`Round Robin`）：顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第七层的故障，`BIG-IP` 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。

比率（`Ratio`）：给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第七层的故障，`BIG-IP` 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。

优先权（`Priority`）：给所有服务器分组,给每个组定义优先权，`BIG-IP` 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，`BIG-IP` 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。

2. 动态负载均衡算法

最少的连接方式（`Least Connection`）：传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。

最快模式（`Fastest`）：传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，`BIG-IP` 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

观察模式（`Observed`）：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

预测模式（`Predictive`）：`BIG-IP`利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被`BIG-IP` 进行检测)

动态性能分配(`Dynamic Ratio-APM`):`BIG-IP` 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。

动态服务器补充(D`ynamic Server Act`):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。

服务质量(`QoS`）:按不同的优先级对数据流进行分配。

服务类型(`ToS`): 按不同的服务类型（在`Type of Field`中标识）负载均衡对数据流进行分配。

规则模式：针对不同的数据流设置导向规则，用户可自行。

#### 缓存

* 分类

1. `CDN`缓存(`Content Delivery Network` 内容分发网络)

主要缓存静态资源，例如图片，视频。

广泛采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区或网络中。

2. 反向代理缓存

一般只缓存体积较小静态文件资源，如 css、js、图片。位于应用服务器机房，处理所有对 `Web` 服务器的请求。

如果用户请求的页面在代理服务器上有缓冲的话，代理服务器直接将缓冲内容发送给用户。

如果没有缓冲则先向 `Web` 服务器发出请求，取回数据，本地缓存后再发送给用户。通过降低向 `Web` 服务器的请求数，从而降低了 `Web` 服务器的负载。

3. 本地应用缓存

指的是在应用中的缓存组件，其最大的优点是应用和 `Cache` 是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等。

在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适。

缺点是缓存与应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。

4. 分布式缓存

指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。

常见的分布式缓存有`Memcached` 和 `Redis`。

* 缓存常见的问题

1. 数据一致性

- 1) 先缓存后写数据库。缓存成功，数据库写入失败，导致脏读。解决方法为先写数据库后缓存。

- 2) 先写数据库后缓存。写数据库成功，缓存失败，导致缓存失效。解决方法为读数据库数据，回写缓存。

- 3) 缓存异步刷新。数据库操作和缓存操作不在同一操作步骤中。解决方法有异步进行缓存刷新，定时刷新等。


2. 缓存穿透

缓存一般是 `Key-Value` 方式存在，当某一个 `Key` 不存在时会查询数据库，假如这个 `Key`一直不存在，则会频繁的请求数据库，对数据库造成访问压力。

主要解决方案：对结果为空的数据也进行缓存，当此 `Key` 有数据后，清理缓存；一定不存在的 `Key`，采用布隆过滤器，建立一个大的 `Bitmap` 中，查询时通过该 `Bitmap` 过滤。

3. 缓存雪崩

缓存失效导致系统性能急剧下降的情况；如高并发业务下并发访问存储系统，更新缓存造成的系统崩溃。

解决方案：对缓存更新操作进行加锁保护，保证只有一个线程在进行缓存更新；后台线程（非业务线程）进行缓存更新，后台线程定时进行，或者业务线程缓存失败后通知后台线程进行缓存更新。

4. 缓存高可用

实现方式：分布式进行数据的海量缓存。复制实现缓存数据节点的高可用。

5. 缓存热点

一些特别热点的数据，高并发访问同一份缓存数据，导致缓存服务器压力过大。

解决方案：复制多份缓存副本，把请求分散到多个缓存服务器上，减轻缓存热点导致的单台缓存服务器压力。

#### 隔离

* 线程池隔离：不同的业务使用不同的线程池，避免低优先级的任务阻塞高优先级的任务。或者高优先级的任务过多，导致低优先级任务永远不会执行。

* 进程隔离：`Linux` 中有用于进程资源隔离的 `Linux CGroup`，通过物理限制的方式为进程间资源控制提供了简单的实现方式，为 `Linux Container` 技术、虚拟化技术的发展奠定了技术基础。

* 模块隔离、应用隔离：很多线上故障的发生源于代码修改后，测试不到位导致。按照代码或业务的易变程度来划分模块或应用，把变化较少的划分到一个模块或应用中，变化较多的划分到另一个模块或应用中。减少代码修改影响的范围，也就减少了测试的工作量，减少了故障出现的概率。

* 读写分离：一方面，将对实时性要求不高的读操作，放到从库上执行，有利于减轻主库的压力。另一方面，将一些耗时离线业务放到从库上执行，能够减少对主库的影响，保证线上业务的稳定可靠。

* 机房隔离

#### 降级

服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。

根据服务方式：可以拒接服务，可以延迟服务，也有时候可以随机服务。

根据服务范围：可以砍掉某个功能，也可以砍掉某些模块。总之服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有好。

#### 限流

限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。

* 常见限流算法

1. 计数器

计数器是最简单粗暴的算法。比如某个服务最多只能每秒钟处理`100`个请求。我们可以设置一个1秒钟的滑动窗口，窗口中有`10`个格子，每个格子`100`毫秒，每`100`毫秒移动一次，每次移动都需要记录当前服务请求的次数。内存中需要保存`10`次的次数。可以用数据结构`LinkedList`来实现。格子每次移动的时候判断一次，当前访问次数和`LinkedList`中最后一个相差是否超过`100`，如果超过就需要限流了。

2. 漏桶算法

漏桶算法即`leaky bucket`是一种非常常用的限流算法，可以用来实现流量整形（`Traffic Shaping`）和流量控制（`Traffic Policing`）。

- 1) 一个固定容量的漏桶，按照常量固定速率流出水滴；
- 2) 如果桶是空的，则不需流出水滴；

- 3) 可以以任意速率流入水滴到漏桶；

- 4) 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。

3. 令牌桶算法

令牌桶算法是一个存放固定容量令牌（`token`）的桶，按照固定速率往桶里添加令牌。

- 1) 令牌将按照固定的速率被放入令牌桶中。比如每秒放`10`个；

- 2) 桶中最多存放`b`个令牌，当桶满时，新添加的令牌被丢弃或拒绝；

- 3) 当一个`n`个字节大小的数据包到达，将从桶中删除`n`个令牌，接着数据包被发送到网络上；

- 4) 如果桶中的令牌不足`n`个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。

#### 熔断

熔断本质上是一个过载保护机制，其指当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护自己以及系统整体的可用性，可以暂时切断对下游服务的调用。

如果调用的远程服务或者资源由于某种原因无法使用时，没有这种过载保护，就会导致请求阻塞在服务器上等待从而耗尽服务器资源。很多时候刚开始可能只是系统出现了局部的、小规模的故障，然而由于种种原因，故障影响的范围越来越大，最终导致了全局性的后果。而这种过载保护就是大家俗称的熔断器(`Circuit Breaker`)。

熔断器的基本原理，包含三个状态：

1. 服务正常运行时的 `Closed` 状态，当服务调用失败量或失败率达到阈值时，熔断器进入 `Open` 状态。

2. 在 `Open` 状态，服务调用不会真正去请求外部资源，会快速失败。

3. 当进入 `Open` 状态一段时间后，进入 `Half-Open` 状态，需要去尝试调用几次服务，检查故障的服务是否恢复。如果成功则熔断器关闭，如果失败，则再次进入 `Open` 状态。

#### 容灾

* 雪崩

服务雪崩效应是一种因服务提供者的不可用导致服务调用者的不可用，并将不可用逐渐放大的过程。

雪崩效应原因：硬件故障、硬件故障、程序`Bug`、重试加大流量、用户大量请求。

雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。

* 异地多活

为了保证系统能够对机房级别的故障进行容错，不会使系统不可用，需要在机房级别对系统进行冗余处理。需要在架构上进行良好的设计，来面对多机房场景下的技术挑战。

#### 平滑启动

#### 分片模式

将一个数据存储到一组水平分区或碎片。存储和访问大量数据时，这个模式可以提高可扩展性。

### 6.1.4 服务治理

#### 服务注册和发现

服务注册就是维护一个登记簿，它管理系统内所有的服务地址。当新的服务启动后，它会向登记簿交待自己的地址信息。服务的依赖方直接向登记簿要`Service Provider`地址就行了。

服务注册一定是要确保高可用的，否则服务调用就会收到影响。重则的是所有的服务都没法调用，轻则新的服务不能上线，假如调用方有缓存服务地址。同时服务注册还要负责一件事情，服务状态的维护。假如一个服务突然`down`掉，它应该能够感知，并把`down`掉的服务摘掉。然后主动或被动的把这个信息告知服务消费方。

* 客户端注册

客户端注册是服务自身要负责注册与注销的工作。当服务启动后向注册中心注册自身，当服务下线时注销自己。期间还需要和注册中心保持心跳。心跳不一定要客户端来做，也可以由注册中心负责（这个过程叫**探活**）。

缺点：注册工作与服务耦合在一起，不同语言都要实现一套注册逻辑。

* 第三方注册

第三方注册由一个独立的服务`Registrar`负责注册与注销。当服务启动后以某种方式通知`Registrar`，然后`Registrar`负责向注册中心发起注册工作。同时注册中心要维护与服务之间的心跳，当服务不可用时，向注册中心注销服务。

缺点：`Registrar`必须是一个高可用的系统，否则注册工作没法进展。

* 客户端服务发现

指客户端负责查询可用服务地址，以及负载均衡的工作。这种方式最方便直接，而且也方便做负载均衡。再者一旦发现某个服务不可用立即换另外一个，非常直接。

缺点：多语言时的重复工作，每个语言实现相同的逻辑。

* 服务器端服务发现

服务端发现需要额外的Router服务，请求先打到Router，然后Router负责查询服务与负载均衡。这种方式虽然没有客户端发现的缺点，但是它的缺点是保证Router的高可用。

* 探活

1. 主动探活

主动探活是由注册中心发起的`service check`的功能。

2. 本地探活

本地探活是在真正的`RPC`调用之前进行探活，这时探活的结果是非常精准的，直接决定当前请求是否可以发送到这台服务器。对于探活失败的服务，本地可以做一个故障投票，然后决定其是否存活。

#### 路由控制

分布式服务架构上线时都是集群组网，这意味着集群中存在某个服务的多实例部署，消费者如何从服务列表中选择合适的服务提供者进行调用，这就涉及到服务路由。分布式服务框架要能够满足用户灵活的路由需求。

* 透明化路由

只需要知道当前系统发布了那些服务，而不需要知道服务具体存在于什么位置。

1. 基于服务注册中心的订阅发布

服务消费者和提供者通过注册中心提供的`SDK`与注册中心建立链路，服务提供者将需要发布的服务地址信息和属性列表写入注册中心。消费者根据本地引用的接口名等信息，从服务注册中心获取服务提供者列表，缓存到本地。

由于消费者可能先于服务提供者启动，或者系统运行过程中新增服务提供者，或者服务提供者宕机退出，就会导致服务注册中心中服务提供者地址发生变更，服务注册中心检测到服务提供者列表发生变化后，会主动将变更后的服务列表推送给消费者，消费者根据新的列表，刷新本地缓存的服务提供者地址。

2. 消费者缓存服务提供者地址

服务消费者调用服务提供者时，不需要每次调用时都去服务注册中心查询服务提供者地址列表，消费者客户端直接从本地缓存的服务提供者路由表中查询地址信息，根据路由策略进行服务选择。

当服务提供者发生变化时，注册中心会主动将变更内容推送给消费者，由后者动态刷新本地库中缓存的路由表，保证服务路由信息的实时准确性。

采用客户端缓存服务提供者地址的方案不仅仅能够提供提升消费者调用性能，还能提高系统的可靠性。当注册中心全部宕机后，消费者可以通过缓存的地址信息和服务提供者之间进行通信，只是影响新服务的上线和老服务的下线，不影响已发布的和运行的服务。

* 分布式服务框架负载均衡策略
 
1. 随机

2. 轮循

3. 服务调用时延

4. 一致性哈希 

相同参数的请求总是发到同一个服务提供者，当某一台提供者宕机时，原本发往该提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动。平台提供默认的虚拟节点数，可以通过配置参数进行修改。 

5. 粘滞连接 

用于连接用于有状态服务，尽可能让客户端总是向同一提供者发起服务调用，除非该提供者宕机，再连接另一台。由于服务通常被强烈建议设计成无状态的，因此，粘滞连接在实际项目中很少使用。

### 6.1.5 分布式一致

#### `CAP`理论和`BASE`理论

#### 分布式锁

#### 分布式一致方案

* 方案

* 一致性算法

* 唯一`ID`

#### 幂等
