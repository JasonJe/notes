## 6.1 分布式系统

>date: 2019-05-06

![](../assets/images/61.jpg)

### 6.1.1 基础理论

分布式系统是作为单个完整服务展现在终端用户面前的一组协同工作服务器。组中的服务器共享状态、同步操作，并且任意某个服务器独立故障时都不会影响整个系统的正常运行。

* 分布式和集群

分布式：将一个业务员拆分不同的子业务，分布在不同的机器上执行；

集群：多台服务器集中在一起，实现同一业务，可以视为一台计算机。

但是分布式的每一个节点，都可以用来做集群，但是集群不一定是分布式的。

* `SOA`和微服务架构

`SOA`：面向服务的架构，这是一种设计理念，其中包含多个服务，服务之间通过相互依赖最终提供一系列完整的功能。

微服务：类似`SOA`架构，但是更加强调业务彻底的组件化和服务化，单个业务系统会被拆分为可以独立开发、设计、部署的小应用。

* `PV`、`TPS`、`QPS`

`PV`：访问量即`Page View`，即页面浏览量或点击量，用户每次刷新即被计算一次。

单台服务器每天PV计算：`每天总PV = QPS * 3600 * 6`；`每天总PV = QPS * 3600 * 8`。

`TPS`：`Transactions Per Second`（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。`业务TPS = CAPS × 每个呼叫平均TPS`。

`TPS`是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力最低模块的`TPS`值。

`QPS`：每秒查询率`QPS`是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应`fetches/sec`，即每秒的响应请求数，也即是最大吞吐能力。

### 6.1.2 可伸缩和可扩展

* 垂直扩展和水平扩展

1. 垂直扩展：在系统现有的部件上下工夫，通过提高某个部件的性能（或速度）来提高负载能力的。

2. 水平扩展：通过增加更多的系统成员（性能或速度还是原来的一样）来提高负载能力的。

* 可伸缩

伸缩性是指在不改变原有架构设计的基础上，通过添加/减少硬件（服务器）的方式，提高/降低系统的处理能力。

1. 应用层：对应用进行垂直或水平切分。然后针对单一功能进行负载均衡（`DNS`,`HTTP`[反向代理],`IP`,链路层）。

2. 服务层：与应用层类似。

3. 数据层：分库，分表，`NOSQL`等；常用算法`Hash`，一致性`Hash`。

* 可扩展

可以方便的进行功能模块的新增/移除，提供代码/模块级别良好的可扩展性。

1. 模块化，组件化：高内聚，内耦合，提高复用性，扩展性。

2. 稳定接口：定义稳定的接口，在接口不变的情况下，内部结构可以“随意”变化。

3. 设计模式：应用面向对象思想，原则，使用设计模式，进行代码层面的设计。

4. 消息队列：模块化的系统，通过消息队列进行交互，使模块之间的依赖解耦。

5. 分布式服务：公用模块服务化，提供其他系统使用，提高可重用性，扩展性。

### 6.1.3 高可用

#### 负载均衡

负载均衡 （`Load Balance`），其意思就是将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行。需要我们注意的是：它并不属于网络基础架构，而是属于一种网络优化设备。它是建立在现有的网络基础架构之上，给企业提供了更廉价更有效的扩展选择。

* 硬件

硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器，由于专门的设 备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求。

优点：能够直接通过智能交换机实现,处理能力更强，而且与系统无关，负载性能强更适用于一大堆设备、大访问量、简单应用。

缺点：成本高，除设备价格高昂，而且配置冗余．很难想象后面服务器做一个集群，但最关键的负载均衡设备却是单点配置；无法有效掌握服务器及应用状态。
硬件负载均衡，一般都不管实际系统与应用的状态，而只是从网络层来判断，所以有时候系统处理能力已经不行了，但网络可能还来得及反应（这种情况非常典型，比如应用服务器后面内存已经占用很多，但还没有彻底不行，如果网络传输量不大就未必在网络层能反映出来）。

* 软件

软件负载均衡解决方案是指在一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。

目前比较流行的就三类软件负载均衡，`LVS`、`Nginx`和`HAProxy`。用的最多的还是`LVS`和`Nginx`这两种。

优点：基于系统与应用的负载均衡，能够更好地根据系统与应用的状况来分配负载。这对于复杂应用是很重要的，性价比高，实际上如果几台服务器，用F5之类的硬件产品显得有些浪费，而用软件就要合算得多，因为服务器同时还可以跑应用做集群等。

缺点：负载能力受服务器本身性能的影响，性能越好，负载能力越大。

* 负载均衡算法

1. 静态负载均衡算法

轮询（`Round Robin`）：顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第七层的故障，`BIG-IP` 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。

比率（`Ratio`）：给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第七层的故障，`BIG-IP` 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

优先权（`Priority`）：给所有服务器分组,给每个组定义优先权，`BIG-IP` 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，`BIG-IP` 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。

2. 动态负载均衡算法

最少的连接方式（`Least Connection`）：传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

最快模式（`Fastest`）：传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，`BIG-IP` 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

观察模式（`Observed`）：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

预测模式（`Predictive`）：`BIG-IP`利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被`BIG-IP` 进行检测)

动态性能分配(`Dynamic Ratio-APM`):`BIG-IP` 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。

动态服务器补充(D`ynamic Server Act`):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。

服务质量(`QoS`）:按不同的优先级对数据流进行分配。

服务类型(`ToS`): 按不同的服务类型（在`Type of Field`中标识）负载均衡对数据流进行分配。

规则模式：针对不同的数据流设置导向规则，用户可自行。

#### 缓存

* 分类

1. `CDN`缓存(`Content Delivery Network` 内容分发网络)

主要缓存静态资源，例如图片，视频。

广泛采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区或网络中。

2. 反向代理缓存

一般只缓存体积较小静态文件资源，如 css、js、图片。位于应用服务器机房，处理所有对 `Web` 服务器的请求。

如果用户请求的页面在代理服务器上有缓冲的话，代理服务器直接将缓冲内容发送给用户。

如果没有缓冲则先向 `Web` 服务器发出请求，取回数据，本地缓存后再发送给用户。通过降低向 `Web` 服务器的请求数，从而降低了 `Web` 服务器的负载。

3. 本地应用缓存

指的是在应用中的缓存组件，其最大的优点是应用和 `Cache` 是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等。

在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适。

缺点是缓存与应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。

4. 分布式缓存

指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。

常见的分布式缓存有`Memcached` 和 `Redis`。

* 缓存常见的问题

1. 数据一致性

- 1) 先缓存后写数据库。缓存成功，数据库写入失败，导致脏读。解决方法为先写数据库后缓存。

- 2) 先写数据库后缓存。写数据库成功，缓存失败，导致缓存失效。解决方法为读数据库数据，回写缓存。

- 3) 缓存异步刷新。数据库操作和缓存操作不在同一操作步骤中。解决方法有异步进行缓存刷新，定时刷新等。


2. 缓存穿透

缓存一般是 `Key-Value` 方式存在，当某一个 `Key` 不存在时会查询数据库，假如这个 `Key`一直不存在，则会频繁的请求数据库，对数据库造成访问压力。

主要解决方案：对结果为空的数据也进行缓存，当此 `Key` 有数据后，清理缓存；一定不存在的 `Key`，采用布隆过滤器，建立一个大的 `Bitmap` 中，查询时通过该 `Bitmap` 过滤。

3. 缓存雪崩

缓存失效导致系统性能急剧下降的情况；如高并发业务下并发访问存储系统，更新缓存造成的系统崩溃。

解决方案：对缓存更新操作进行加锁保护，保证只有一个线程在进行缓存更新；后台线程（非业务线程）进行缓存更新，后台线程定时进行，或者业务线程缓存失败后通知后台线程进行缓存更新。

4. 缓存高可用

实现方式：分布式进行数据的海量缓存。复制实现缓存数据节点的高可用。

5. 缓存热点

一些特别热点的数据，高并发访问同一份缓存数据，导致缓存服务器压力过大。

解决方案：复制多份缓存副本，把请求分散到多个缓存服务器上，减轻缓存热点导致的单台缓存服务器压力。

#### 隔离

* 线程池隔离：不同的业务使用不同的线程池，避免低优先级的任务阻塞高优先级的任务。或者高优先级的任务过多，导致低优先级任务永远不会执行。

* 进程隔离：`Linux` 中有用于进程资源隔离的 `Linux CGroup`，通过物理限制的方式为进程间资源控制提供了简单的实现方式，为 `Linux Container` 技术、虚拟化技术的发展奠定了技术基础。

* 模块隔离、应用隔离：很多线上故障的发生源于代码修改后，测试不到位导致。按照代码或业务的易变程度来划分模块或应用，把变化较少的划分到一个模块或应用中，变化较多的划分到另一个模块或应用中。减少代码修改影响的范围，也就减少了测试的工作量，减少了故障出现的概率。

* 读写分离：一方面，将对实时性要求不高的读操作，放到从库上执行，有利于减轻主库的压力。另一方面，将一些耗时离线业务放到从库上执行，能够减少对主库的影响，保证线上业务的稳定可靠。

* 机房隔离

#### 降级

服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。

根据服务方式：可以拒接服务，可以延迟服务，也有时候可以随机服务。

根据服务范围：可以砍掉某个功能，也可以砍掉某些模块。总之服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有好。

#### 限流

限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。

* 常见限流算法

1. 计数器

计数器是最简单粗暴的算法。比如某个服务最多只能每秒钟处理`100`个请求。我们可以设置一个1秒钟的滑动窗口，窗口中有`10`个格子，每个格子`100`毫秒，每`100`毫秒移动一次，每次移动都需要记录当前服务请求的次数。内存中需要保存`10`次的次数。可以用数据结构`LinkedList`来实现。格子每次移动的时候判断一次，当前访问次数和`LinkedList`中最后一个相差是否超过`100`，如果超过就需要限流了。

2. 漏桶算法

漏桶算法即`leaky bucket`是一种非常常用的限流算法，可以用来实现流量整形（`Traffic Shaping`）和流量控制（`Traffic Policing`）。

- 1) 一个固定容量的漏桶，按照常量固定速率流出水滴；
- 2) 如果桶是空的，则不需流出水滴；

- 3) 可以以任意速率流入水滴到漏桶；

- 4) 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。

3. 令牌桶算法

令牌桶算法是一个存放固定容量令牌（`token`）的桶，按照固定速率往桶里添加令牌。

- 1) 令牌将按照固定的速率被放入令牌桶中。比如每秒放`10`个；

- 2) 桶中最多存放`b`个令牌，当桶满时，新添加的令牌被丢弃或拒绝；

- 3) 当一个`n`个字节大小的数据包到达，将从桶中删除`n`个令牌，接着数据包被发送到网络上；

- 4) 如果桶中的令牌不足`n`个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。

#### 熔断

熔断本质上是一个过载保护机制，其指当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护自己以及系统整体的可用性，可以暂时切断对下游服务的调用。

如果调用的远程服务或者资源由于某种原因无法使用时，没有这种过载保护，就会导致请求阻塞在服务器上等待从而耗尽服务器资源。很多时候刚开始可能只是系统出现了局部的、小规模的故障，然而由于种种原因，故障影响的范围越来越大，最终导致了全局性的后果。而这种过载保护就是大家俗称的熔断器(`Circuit Breaker`)。

熔断器的基本原理，包含三个状态：

1. 服务正常运行时的 `Closed` 状态，当服务调用失败量或失败率达到阈值时，熔断器进入 `Open` 状态。

2. 在 `Open` 状态，服务调用不会真正去请求外部资源，会快速失败。

3. 当进入 `Open` 状态一段时间后，进入 `Half-Open` 状态，需要去尝试调用几次服务，检查故障的服务是否恢复。如果成功则熔断器关闭，如果失败，则再次进入 `Open` 状态。

#### 容灾

* 雪崩

服务雪崩效应是一种因服务提供者的不可用导致服务调用者的不可用，并将不可用逐渐放大的过程。

雪崩效应原因：硬件故障、硬件故障、程序`Bug`、重试加大流量、用户大量请求。

雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。

* 异地多活

为了保证系统能够对机房级别的故障进行容错，不会使系统不可用，需要在机房级别对系统进行冗余处理。需要在架构上进行良好的设计，来面对多机房场景下的技术挑战。

#### 平滑启动

#### 分片模式

将一个数据存储到一组水平分区或碎片。存储和访问大量数据时，这个模式可以提高可扩展性。

### 6.1.4 服务治理

#### 服务注册和发现

服务注册就是维护一个登记簿，它管理系统内所有的服务地址。当新的服务启动后，它会向登记簿交待自己的地址信息。服务的依赖方直接向登记簿要`Service Provider`地址就行了。

服务注册一定是要确保高可用的，否则服务调用就会收到影响。重则的是所有的服务都没法调用，轻则新的服务不能上线，假如调用方有缓存服务地址。同时服务注册还要负责一件事情，服务状态的维护。假如一个服务突然`down`掉，它应该能够感知，并把`down`掉的服务摘掉。然后主动或被动的把这个信息告知服务消费方。

* 客户端注册

客户端注册是服务自身要负责注册与注销的工作。当服务启动后向注册中心注册自身，当服务下线时注销自己。期间还需要和注册中心保持心跳。心跳不一定要客户端来做，也可以由注册中心负责（这个过程叫**探活**）。

缺点：注册工作与服务耦合在一起，不同语言都要实现一套注册逻辑。

* 第三方注册

第三方注册由一个独立的服务`Registrar`负责注册与注销。当服务启动后以某种方式通知`Registrar`，然后`Registrar`负责向注册中心发起注册工作。同时注册中心要维护与服务之间的心跳，当服务不可用时，向注册中心注销服务。

缺点：`Registrar`必须是一个高可用的系统，否则注册工作没法进展。

* 客户端服务发现

指客户端负责查询可用服务地址，以及负载均衡的工作。这种方式最方便直接，而且也方便做负载均衡。再者一旦发现某个服务不可用立即换另外一个，非常直接。

缺点：多语言时的重复工作，每个语言实现相同的逻辑。

* 服务器端服务发现

服务端发现需要额外的`Router`服务，请求先打到`Router`，然后`Router`负责查询服务与负载均衡。这种方式虽然没有客户端发现的缺点，但是它的缺点是保证Router的高可用。

* 探活

1. 主动探活

主动探活是由注册中心发起的`service check`的功能。

2. 本地探活

本地探活是在真正的`RPC`调用之前进行探活，这时探活的结果是非常精准的，直接决定当前请求是否可以发送到这台服务器。对于探活失败的服务，本地可以做一个故障投票，然后决定其是否存活。

#### 路由控制

分布式服务架构上线时都是集群组网，这意味着集群中存在某个服务的多实例部署，消费者如何从服务列表中选择合适的服务提供者进行调用，这就涉及到服务路由。分布式服务框架要能够满足用户灵活的路由需求。

* 透明化路由

只需要知道当前系统发布了那些服务，而不需要知道服务具体存在于什么位置。

1. 基于服务注册中心的订阅发布

服务消费者和提供者通过注册中心提供的`SDK`与注册中心建立链路，服务提供者将需要发布的服务地址信息和属性列表写入注册中心。消费者根据本地引用的接口名等信息，从服务注册中心获取服务提供者列表，缓存到本地。

由于消费者可能先于服务提供者启动，或者系统运行过程中新增服务提供者，或者服务提供者宕机退出，就会导致服务注册中心中服务提供者地址发生变更，服务注册中心检测到服务提供者列表发生变化后，会主动将变更后的服务列表推送给消费者，消费者根据新的列表，刷新本地缓存的服务提供者地址。

2. 消费者缓存服务提供者地址

服务消费者调用服务提供者时，不需要每次调用时都去服务注册中心查询服务提供者地址列表，消费者客户端直接从本地缓存的服务提供者路由表中查询地址信息，根据路由策略进行服务选择。

当服务提供者发生变化时，注册中心会主动将变更内容推送给消费者，由后者动态刷新本地库中缓存的路由表，保证服务路由信息的实时准确性。

采用客户端缓存服务提供者地址的方案不仅仅能够提供提升消费者调用性能，还能提高系统的可靠性。当注册中心全部宕机后，消费者可以通过缓存的地址信息和服务提供者之间进行通信，只是影响新服务的上线和老服务的下线，不影响已发布的和运行的服务。

* 分布式服务框架负载均衡策略
 
1. 随机

2. 轮循

3. 服务调用时延

4. 一致性哈希 

相同参数的请求总是发到同一个服务提供者，当某一台提供者宕机时，原本发往该提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动。平台提供默认的虚拟节点数，可以通过配置参数进行修改。 

5. 粘滞连接 

用于连接用于有状态服务，尽可能让客户端总是向同一提供者发起服务调用，除非该提供者宕机，再连接另一台。由于服务通常被强烈建议设计成无状态的，因此，粘滞连接在实际项目中很少使用。

### 6.1.5 分布式一致

#### `CAP`理论和`BASE`理论

* `CAP`理论

1. 一致性(`C：Consistency`)

在分布式环境下，一致性是指数据在多个副本之间能否保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。

在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到其最新的值，那么这样的系统就被认为具有强一致性。

2、可用性(`A：Availability`)

可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。这里的重点是"有限时间内"和"返回结果"。

"有限时间内"是指，对于用户的一个操作请求，系统必须能够在指定的时间内返回对应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可用的。

另外，"有限的时间内"是指系统设计之初就设计好的运行指标，通常不同系统之间有很 大的不同，无论如何，对于用户请求，系统必须存在一个合理的响应时间，否则用户便会对系统感到失望。

"返回结果"是可用性的另一个非常重要的指标，它要求系统在完成对用户请求的处理后，返回一个正常的响应结果。正常的响应结果通常能够明确地反映出队请求的处理结果，即成功或失败，而不是一个让用户感到困惑的返回结果。

3、分区容错性(`P：Partition tolerance`)

分区容错性约束了一个分布式系统具有如下特性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。

网络分区是指在分布式系统中，不同的节点分布在不同的子网络（机房或异地网络） 中，由于一些特殊的原因导致这些子网络出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。需要注意的是，组成一个分布式系统的每个节点的加入与退出都可以看作是一个特殊的网络分区。

一个分布式系统不可能同时满足一致性（C:Consistency）、可用性（A:Availability）和分区容错性（P:Partition tolerance）这三个基本要求，最多只能满足其中的两项。

一个分布式系统不可能同时满足一致性(`C：Consistency`)、可用性(`A：Availability`)和分区容错性(`P：Partition tolerance`)这三个基本需求，最多只能同时满足其中两项。

放弃`P`：

如果希望能够避免系统出现分区容错性问题，一种较为简单的做法是将所有的数据（或者仅仅是哪些与事务相关的数据）都放在一个分布式节点上。这样做虽然无法100%保证系统不会出错，但至少不会碰到由于网络分区带来的负面影响。但同时需要注意的是，放弃P的同时也就意味着放弃了系统的可扩展性

放弃`A`：

一旦系统遇到网络分区或其他故障或为了保证一致性时，放弃可用性，那么受到影响的服务需要等待一定的时间，因此在等待期间系统无法对外提供正常的服务，即不可用

放弃`C`：

这里所说的放弃一致性，实际上指的是放弃数据的强一致性，而保留数据的最终一致性。这样的系统无法保证数据保持实时的一致性，但是能够承诺的是，数据最终会达到一个一致的状态。

* `BASE`理论

`BASE`是基本可用(`Basically Available`)、软状态(`Soft state`)和最终一致性(`Eventually consistent`)三个短语的缩写。

`BASE`理论是对`CAP`中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结， 是基于`CAP`定理逐步演化而来的。

`BASE`理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。

1. 基本可用(`Basically Available`)

指分布式系统在出现不可预知故障的时候，允许损失部分可用性。

2. 软状态(`Soft state`)

允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同的数据副本之间进行数据同步的过程存在延时。

3. 最终一致性(`Eventually consistent`)

最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。

#### 分布式锁

分布式锁，是控制分布式系统之间同步访问共享资源的一种方式。

在分布式系统中，常常需要协调他们的动作。如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，在这种情况下，便需要使用到分布式锁。

* 常见的分布式锁实现方式

1. 基于数据库实现

- 1) 在数据库中创建锁表，当要锁住某个方法或资源时，就往该表中增加一条记录，想要释放锁的时候就删除这条记录。

- 2) 基于数据库排他锁

基于`MySQL`的`InnoDB`引擎，可以使用以下方法来实现加锁操作。

```sql
select * from methodLock where method_name=xxx for update;
```

当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。

可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再进行解锁。

2. 基于缓存实现

基于缓存实现分布式锁比基于数据库实现分布式锁性能上表现更好一些，同时缓存可以集群部署，可以解决单点问题。

以`Redis`为例，其实现分布式锁的过程如下：

- 1) 获取锁的时候，使用`SETNX`加锁，并使用`EXPIRE`命令设置一个超时时间，超过时间自动释放锁，锁的值为`UUID`,在释放锁的时候判断；

- 2) 释放锁的时候，通过`UUID`判断是不是该锁，若是则进行`DELETE`操作进行锁的释放。

3. 基于`ZooKeeper`实现

每个客户端对某个方法加锁时，在`ZooKeeper`上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 

判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。

当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。

#### 分布式一致方案

* 方案

[保证分布式系统数据一致性的6种方案](https://weibo.com/ttarticle/p/show?id=2309403965965003062676)

* 一致性算法

1. `Paxos`算法

2. `Zab`协议

3. `Raft`协议

4. `Gossip`算法

5. 两阶段提交、多阶段提交

* 唯一`ID`

[高并发分布式系统中生成全局唯一Id汇总](https://www.cnblogs.com/baiwa/p/5318432.html)

#### 幂等

`Web`资源或`API`方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。幂等性是系统的接口对外一种承诺(而不是实现)，承诺只要调用接口成功，外部多次调用对系统的影响是一致的。幂等性是分布式系统设计中的一个重要概念，对超时处理、系统恢复等具有重要意义。

声明为幂等的接口会认为外部调用失败是常态，并且失败之后必然会有重试。例如，在因网络中断等原因导致请求方未能收到请求返回值的情况下，如果该资源具备幂等性，请求方只需要重新请求即可，而无需担心重复调用会产生错误。

常见用来保证幂等的手段：

1. 多版本并发控制(`MVCC`)

2. 去重表

在插入数据的时候，插入去重表，利用数据库的唯一索引特性，保证唯一的逻辑。

3. 悲观锁

4. `select + insert`

并发不高的后台系统，或者一些任务，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过。注意：核心高并发流程不要用这种方法。

5.状态机幂等

在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。

6. `token`机制，防止页面重复提交

业务要求：页面的数据只能被点击提交一次；

发生原因：由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交；

解决办法：采用`token`加`Redis`（`Redis`单线程的，处理需要排队）；

处理流程：数据提交前要向服务的申请`token`，`token`放到`Redis`，token设置有效时间，提交后后台校验`token`，同时删除`token`，生成新的`token`返回。

7. 对外提供接口的`API`如何保证幂等 

如银联提供的付款接口：需要接入商户提交付款请求时附带：`source`来源，`seq`序列号。`source+seq`在数据库里面做唯一索引，防止多次付款(并发时，只能处理一个请求)。