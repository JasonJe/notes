## 8.1 基础概念

>date: 2019-06-12

![](../assets/images/81.jpg)

### 8.1.1 概述

* 机器学习的分类

1. 监督学习

指利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的过程。

从有标签的训练数据中学习模型，对未来未知的数据进行预测。

2. 无监督学习

指针对一组不知道类别的样本进行自动的分类或者划分的过程。

从无标签的数据中，利用相关方法寻找数据中隐藏的结构。

3. 半监督学习

是监督学习与无监督学习相结合的一种学习方法。使用大量的未标记数据，以及同时使用标记数据，来进行模式识别工作。

4. 强化学习

一直激励学习的方式，通过激励函数来让模型不断根据遇到的情况做出调整。

* 机器学习流程

实际问题抽象成数学问题 --> 数据集获取 --> 特征工程 --> 模型训练与调优 --> 模型评估 --> 模型预测

![机器学习流程](../assets/images/811_01.png)

* 数据集

用来进行机器学习的一个数据集往往会被分为两个数据集——测试集（`training data`）和测试集（`testing data`）。 

如果在训练的过程中需要确定方法的准确度，有时会将训练数据分成训练集（`training set`）和验证集（`validation set`）。

训练集是在机器学习的过程中使用，目的是找出一套机器学习的模型；

测试集用于判断学习的模型是否足够有效，其在模型建立后才被使用的。

验证集与测试集不同的地方在于验证集在训练过程中使用，用于相关参数的调节。

### 8.1.2 模型评估

#### 分类指标

二分类问题中，其类别可以划分为正例（`Positive Class`）和反例（`Negative Class`）。

* 混淆矩阵（Confusion Matrix）：

![混淆矩阵](../assets/images/811_02.png)

1. `True Positive`(真正, `TP`)：将正类预测为正类数；

2. `True Negative`(真负, `TN`)：将负类预测为负类数；

3. `False Positive`(假正, `FP`)：将负类预测为正类数 → 误报 (`Type I error`)；

4. `False Negative`(假负, `FN`)：将正类预测为负类数 → 漏报 (`Type II error`)。

* 准确率（`Accuracy`）是预测和标签一致的样本在所有样本中所占的比例：

$$ ACC = \frac{TP + TN}{TP + TN + FP + FN} $$

* 精确率（`Precision`）是预测为正类的数据中，有多少确实是正类：

$$ P = \frac{TP}{TP + FP} $$

* 召回率（`Recall`）是所有正类的数据中，预测为正类的数据有多少：

$$ R = \frac{TP}{TP + FN} $$

* $F_1$值是精确率和召回率的调和均值（精确率和准确率都高的情况下，$F_1$值也会高。）：

$$ F_1 = \frac{2TP}{2TP + FP + FN} $$

* `ROC`曲线（受试者工作特征曲线、感受性曲线）

![ROC曲线](../assets/images/811_03.jpg)

其是横轴为`FRP`，纵轴为`TPR`组成的图形，其中

$$ TPR = \frac{TP}{TP + FN} $$

代表正例分对的概率。

$$ FRP = \frac{FP}{FP + TN} $$

代表将负例错分为正例的概率。

* `AUC`定义为`ROC`曲线下的面积：

`AUC`值越大的分类器，正确率越高。

1. `AUC=1`，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器；

2. `0.5<AUC<1`，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值；

3. `AUC=0.5`，跟随机猜测一样（例：丢铜板），模型没有预测价值；

4. `AUC<0.5`，比随机猜测还差；但只要总是反预测而行，就优于随机猜测，因此不存在 `AUC<0.5` 的情况。

#### 回归指标

回归问题通常会计算误差来确定模型的精确性，又根据训练集和验证集的不同，分为训练误差和验证误差。同时根据衡量模型泛化误差的不同方面，又有偏差和方差。泛化误差可以分解为偏差、方差和噪声之和。

**偏差**指的是模型预测的期望值与真实值之间的差，用于描述模型的拟合能力；**方差**指的是模型预测的期望值和预测值之间的差平方和，用于描述模型的稳定性。

偏差过大会导致模型**欠拟合**，而方差过大会导致模型**过拟合**，泛化能力下降。

![拟合](../assets/images/811_04.png)

* 平均绝对误差($l_1$范数损失)

$$MAE(y, \hat{y}) = \frac{1}{n}\sum_{i = 1}^{n}|y_i - \hat y_i|$$

* 平均平方误差($l_2$范数损失)

$$MSE(y, \hat y) = \frac{1}{n}\sum_{i = 1}^{n}(y_i - \hat y_i)^2$$

#### 交叉检验

1. 留出法

将数据集分为训练集和测试集，使用训练集训练模型后，使用测试集进行模型性能评价。

2. `K`折交叉检验

将数据集分为`K`份，按次序选择一份作为测试集，其它`K-1`份作为训练集训练模型并对利用测试集进行评价，综合`K`次的结果，选择损失函数评估最优的模型和参数。

3. 自助法`Boostraping`

`n`个样本的样本集，重复有放回采样`n`次，构成测试集。样本作为训练集。

### 8.1.3 特征工程

* 特征缩放

1. 归一化（标准化）

- * 线性归一化

$$X = \frac{X - X_{min}}{X_{max} - X_{min}}$$

对原始数据进行线性变换，使得结果映射到$[0,1]$的范围。

- * 零均值归一化(`Z-Score`)

$$z = \frac{x - \mu}{\sigma}$$

将原始数据映射到均值为 `0`，标准差为 `1` 的分布上。

2. 正则化

假设数据集为：

$$D = \{({\mathbf{x_1}, y_1}), ({\mathbf{x_2}, y_2}), ... ({\mathbf{x_N}, y_N})\}, \mathbf{x_i} = (x_i^{(1)}, x_i^{(2)}, ..., x_i^{(d)})^T$$

对样本计算$L_p$范数，得到

$$L_p(\mathbf{x_i}) = (|x_i^{(1)}|^p, |x_i^{(2)}|^p, ... |x_i^{(d)}|^p)^{\frac{1}{p}}$$

正则化的结果为：

$$\mathbf{x_i} = (\frac{x_i^{(1)}}{L_p(x_i)}, \frac{x_i^{(2)}}{L_p(x_i)}, ..., \frac{x_i^{(d)}}{L_p(x_i)})^T$$

正则化的过程是针对单个样本的，对每个样本将它缩放到单位范数。通常如果使用二次型（如点积）或者其他核方法计算两个样本之间的相似性时，该方法会很有用。

* 特征编码

1. 序号编码

处理类别间具有大小关系的数据。

将中文的"高>中>低"的大小关系转化为"3>2>1"的编码。

2. 独热编码

处理类别间不具有大小关系的特征。

如将血型`A`、`B`、`AB` 以及 `O` 型转为`4`维的稀疏向量。

`A`型：`(1,0,0,0)`、`B`型：`(0,1,0,0)`、`AB`型：`(0,0,1,0)`、`O`型：`(0,0,0,1)`。

3. 二进制编码

先采用序号编码给每个类别赋予一个类别 `ID`；接着将类别 `ID` 对应的二进制编码作为结果。

本质上是利用二进制对类别 `ID` 进行哈希映射，最终得到 `0/1` 特征向量，并且特征维度小于独热编码，更加节省存储空间。

4. 二元化

将数值型的属性转换为布尔型的属性。通常用于假设属性取值分布是伯努利分布的情形。

对属性 `j` 指定一个阈值 `m`。

如果样本在属性 `j` 上的值大于等于 `m`, 则二元化后为 1；如果样本在属性 `j` 上的值小于 `m`，则二元化为 `0`

5. 离散化

连续数据经常采用离散化处理之后再放入模型。离散化可以理解为提取特征的过程，比如在`LR`模型，由于是广义线性模型表达能力有限，因此通过特征离散化来了提高非线性学习能力。

等距离散：取值范围均匀划成`n`等份，每份的间距相等；

等频离散：均匀分为`n`等份，每份包含的观察点数相同。

* 特征选择

* `Embedding`

### 8.1.4 优化算法