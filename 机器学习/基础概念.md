## 8.1 基础概念

>date: 2019-06-12

![](../assets/images/81.jpg)

### 8.1.1 概述

* 机器学习的分类

1. 监督学习

指利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的过程。

从有标签的训练数据中学习模型，对未来未知的数据进行预测。

2. 无监督学习

指针对一组不知道类别的样本进行自动的分类或者划分的过程。

从无标签的数据中，利用相关方法寻找数据中隐藏的结构。

3. 半监督学习

是监督学习与无监督学习相结合的一种学习方法。使用大量的未标记数据，以及同时使用标记数据，来进行模式识别工作。

4. 强化学习

一直激励学习的方式，通过激励函数来让模型不断根据遇到的情况做出调整。

* 机器学习流程

实际问题抽象成数学问题 --> 数据集获取 --> 特征工程 --> 模型训练与调优 --> 模型评估 --> 模型预测

![机器学习流程](../assets/images/811_01.png)

* 数据集

用来进行机器学习的一个数据集往往会被分为两个数据集——测试集（`training data`）和测试集（`testing data`）。 

如果在训练的过程中需要确定方法的准确度，有时会将训练数据分成训练集（`training set`）和验证集（`validation set`）。

训练集是在机器学习的过程中使用，目的是找出一套机器学习的模型；

测试集用于判断学习的模型是否足够有效，其在模型建立后才被使用的。

验证集与测试集不同的地方在于验证集在训练过程中使用，用于相关参数的调节。

### 8.1.2 模型评估

二分类问题中，其类别可以划分为正例（`Positive Class`）和反例（`Negative Class`）。

* 混淆矩阵（Confusion Matrix）：

![混淆矩阵](../assets/images/811_02.png)

1. `True Positive`(真正, `TP`)：将正类预测为正类数；

2. `True Negative`(真负, `TN`)：将负类预测为负类数；

3. `False Positive`(假正, `FP`)：将负类预测为正类数 → 误报 (`Type I error`)；

4. `False Negative`(假负, `FN`)：将正类预测为负类数 → 漏报 (`Type II error`)。

* 准确率（`Accuracy`）是预测和标签一致的样本在所有样本中所占的比例：

$$ ACC = \frac{TP + TN}{TP + TN + FP + FN} $$

* 精确率（`Precision`）是预测为正类的数据中，有多少确实是正类：

$$ P = \frac{TP}{TP + FP} $$

* 召回率（`Recall`）是所有正类的数据中，预测为正类的数据有多少：

$$ R = \frac{TP}{TP + FN} $$

* $F_1$值是精确率和召回率的调和均值（精确率和准确率都高的情况下，$F_1$值也会高。）：

$$ F_1 = \frac{2TP}{2TP + FP + FN} $$

* `ROC`曲线（受试者工作特征曲线、感受性曲线）

![ROC曲线](../assets/images/811_03.jpg)

其是横轴为`FRP`，纵轴为`TPR`组成的图形，其中

$$ TPR = \frac{TP}{TP + FN} $$

代表正例分对的概率。

$$ FRP = \frac{FP}{FP + TN} $$

代表将负例错分为正例的概率。

* `AUC`定义为`ROC`曲线下的面积：

`AUC`值越大的分类器，正确率越高。

1. `AUC=1`，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器；

2. `0.5<AUC<1`，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值；

3. `AUC=0.5`，跟随机猜测一样（例：丢铜板），模型没有预测价值；

4. `AUC<0.5`，比随机猜测还差；但只要总是反预测而行，就优于随机猜测，因此不存在 `AUC<0.5` 的情况。

### 8.1.3 特征工程

### 8.1.4 优化算法